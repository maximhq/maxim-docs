---
title: "OpenAI SDK"
description: "Learn how to integrate Maxim observability with the OpenAI SDK in just one line of code."
---

## Requirements

```
"openai>=1.65.4"
"maxim-py>=3.5.0"
```

## Env variables

```
MAXIM_API_KEY=
MAXIM_LOG_REPO_ID=
OPENAI_API_KEY=
```

## Initialize logger

```python
import maxim from Maxim

logger = Maxim().logger()
```

## Initialize MaximOpenAIClient

```python {4}
from openai import OpenAI
from maxim.logger.openai import MaximOpenAIClient

client = MaximOpenAIClient(client=OpenAI(api_key=OPENAI_API_KEY),logger=logger)
```

## Make LLM calls using MaximOpenAIClient

```python {4}
from openai import OpenAI
from maxim.logger.openai import MaximOpenAIClient

client = MaximOpenAIClient(client=OpenAI(api_key=OPENAI_API_KEY),logger=logger)

messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Write a haiku about recursion in programming."},
]

# Create a chat completion request
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=messages,        
)
# Extract response text and usage
response_text = response.choices[0].message.content
print(response_text)
```

![Demo](/images/docs/sdk/python/openai/py-openai-integration.gif)


<CardGroup cols={2}>
  <Card title="OpenAI one line integration cookbook" icon="github" href="https://github.com/maximhq/maxim-cookbooks/blob/main/python/observability-online-eval/openai/openai-sdk/one-line-integration.ipynb">
    
  </Card>
  <Card title="OpenAI one line integration cookbook" icon="g" href="https://colab.research.google.com/github/maximhq/maxim-cookbooks/blob/main/python/observability-online-eval/openai/openai-sdk/one-line-integration.ipynb?authuser=1#scrollTo=0XWIM8tvNg6u">
    
  </Card>
</CardGroup>


## Advanced use-cases

### Capture multiple LLM calls in one trace

<Steps>
  <Step title="Initialize Maxim SDK and OpenAI Client">
    ```python
    from openai import OpenAI
    from maxim import Maxim
    from maxim.logger.openai import MaximOpenAIClient
    
    # Make sure MAXIM_API_KEY and MAXIM_LOG_REPO_ID are set in env variables
    logger = Maxim().logger()
    
    # Initialize MaximOpenAIClient
    client = MaximOpenAIClient(client=OpenAI(api_key=OPENAI_API_KEY),logger=logger)
    ```
  </Step>
  <Step title="Create a new trace externally">
    ```python
    from uuid import uuid4
    
    trace_id = str(uuid4())
    
    trace = logger.trace({
    	id: trace_id,
    	name: "Trace name"
    })
    ```
  </Step>
  <Step title="Make LLM calls and use this trace id">
    ```python
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,   
    	extra_headers={"x-maxim-trace-id": trace_id}
    )
    # Extract response text and usage
    response_text = response.choices[0].message.content
    print(response_text)
    ```
  </Step>
  <Step title="Keep adding LLM calls">
    All LLM calls with extra header `maxim_trace_id: trace_id` will add it the declared trace.
  </Step>
</Steps>

### Capture multi-turn conversations

<Steps>
  <Step title="Initialize Maxim SDK and OpenAI Client">
    ```python
    from openai import OpenAI
    from maxim import Maxim
    from maxim.logger.openai import MaximOpenAIClient
    
    # Make sure MAXIM_API_KEY and MAXIM_LOG_REPO_ID are set in env variables
    logger = Maxim().logger()
    
    # Initialize MaximOpenAIClient
    client = MaximOpenAIClient(client=OpenAI(api_key=OPENAI_API_KEY),logger=logger)
    ```
  </Step>
  <Step title="Create a new trace externally and add it to a session">
    ```python
    from uuid import uuid4

    # use this session id to add multiple traces in one session
    session_id = str(uuid4())
    
    trace_id = str(uuid4())

    
    trace = logger.trace({
    	id: trace_id,
    	name: "Trace name",
        session_id: session_id
    })
    ```
  </Step>
  <Step title="Make LLM calls and use this trace id">
    ```python
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,   
    	extra_headers={"x-maxim-trace-id": trace_id}
    )
    # Extract response text and usage
    response_text = response.choices[0].message.content
    print(response_text)
    ```
  </Step>
</Steps>