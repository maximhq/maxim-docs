---
title: Overview
description: Monitor AI applications in real-time with Maxim's enterprise-grade LLM observability platform.
---

import { MaximPlayer } from "/snippets/maximPlayer.mdx"

## Improve your AI application outcomes

Build and monitor reliable AI applications for consistent results:
- Monitor AI model performance in production
- Detect and resolve issues proactively
- Improve response quality through data-driven insights
- Reduce costs with optimized resource usage

## Understanding LLM observability challenges

Why traditional monitoring fails LLM applications:

- Cannot track prompt and completion correlations
- Cannot monitor critical LLM metrics (token usage, model parameters, response quality)
- Struggles to process structured and unstructured data effectively
- Cannot trace reasoning or debug black-box LLM failures
- Fail to track complex workflows with RAG, tools, and multi-step reasoning
- Provide limited support for human feedback and preference models
- Lack subjective metric tracking for user ratings and A/B tests

## Maxim's solution

![Maxim platform architecture overview](/images/docs/observe/overview/observe.png)

Maxim platform leverages three core architectural principles:

### 1. Comprehensive distributed tracing

Track the complete request lifecycle, including LLM requests and responses. Debug precisely with end-to-end application flow visibility.

### 2. Zero-state SDK architecture

Maintain robust observability across functions, classes, and microservices without state management complexity.

### 3. Open source compatibility

Maxim logging is inspired by (and highly compatible with) open telemetry:
- Generate idempotent commit logs for every function call
- Support high concurrency and network instability
- Maintain accurate trace timelines regardless of log arrival order
- Production-proven reliability with over one billion indexed logs

## Key Features

### Real-time monitoring and alerting
Track GenAI metrics through distributed tracing and receive instant alerts via:
- Slack
- PagerDuty
- OpsGenie

Monitor critical thresholds for:
- Cost per trace
- Token usage
- User feedback patterns

<MaximPlayer url="https://drive.google.com/file/d/1Rqqt9WdUBgM8OtsX9ciKEOSOQpKT72CM/preview"/>

### Saved views
Find common search patterns instantly:
- Store common search patterns
- Create debugging shortcuts
- Speed up issue resolution

<MaximPlayer url="https://drive.google.com/file/d/1HMc0wNdZdgz2SvZbYgfeD3CAeFLyDH1R/preview"/>

### Online evaluation
Monitor application performance with:
- Custom filters and rules
- Automated reports
- Threshold-based alerts

<MaximPlayer url="https://drive.google.com/file/d/1e0zAhfpwUpbdKv7xkAjb-42xGVY3zUJr/preview"/>

### Data curation
Transform logs into valuable datasets:
- Create datasets with one click
- Filter incoming logs
- Build targeted training data
- Update datasets for prompt improvements

<MaximPlayer url="https://drive.google.com/file/d/1r3eO0f0yuzZ3rPZUUw9k0HGfpCVePiNH/preview"/>